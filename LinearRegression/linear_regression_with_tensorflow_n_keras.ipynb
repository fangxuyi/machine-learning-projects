{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d446f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current tensorflow version is:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Your current tensorflow version is: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9743532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2829215767029443220\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385f9477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2dc2c",
   "metadata": {},
   "source": [
    "## Tensor: Multi dimensional array used in Tensorflow\n",
    "- Constant\n",
    "- Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671ac9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554e2f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your tensor rank is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(3)\n",
    "print(\"your tensor rank is {}\".format(tf.rank(a)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ecebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your tensor rank is 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [0, 0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([[1,2],[0,0]])\n",
    "print(\"your tensor rank is {}\".format(tf.rank(b)))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7f8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your tensor rank is 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[0.27137952, 0.89933453],\n",
       "       [0.10702267, 0.003717  ]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(np.random.rand(2,2))\n",
    "print(\"your tensor rank is {}\".format(tf.rank(c)))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40df8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b3977d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(a)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a53ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.constant([[1,2],\n",
    "                 [3,4]])\n",
    "print(b)\n",
    "\n",
    "b = tf.cast(b, dtype = tf.float32)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3d285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(27, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2)\n",
    "y = tf.Variable(5)\n",
    "f = x * x * y + y + 2\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347d0e7",
   "metadata": {},
   "source": [
    "## Common operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6c7840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_test = tf.constant([[1,2],\n",
    "                          [3,4]])\n",
    "tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d48f121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9de553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1109f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 7,  8],\n",
       "       [ 9, 10]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcastingï¼štrailing dimension are the same or one of them is 1\n",
    "tensor_test = tensor_test + 6\n",
    "tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bd343c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 1,  4],\n",
       "       [ 9, 16]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_test = tf.constant([[1,2],\n",
    "                          [3,4]])\n",
    "\n",
    "tensor_test = tf.square(tensor_test)\n",
    "tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b31a5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sqrt must be on float\n",
    "tensor_test = tf.constant([[1. ,4. ],\n",
    "                          [9. ,16. ]])\n",
    "tensor_test = tf.sqrt(tensor_test)\n",
    "tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c1dcdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 7., 10.],\n",
       "       [15., 22.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_test = tf.matmul(tensor_test, tensor_test)\n",
    "tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c14e26d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  16],\n",
       "       [ 81, 256]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy functions can be applied on tensor. numpy array is returned\n",
    "tensor_test = tf.constant([[1,4],\n",
    "                           [9,16]])\n",
    "np.square(tensor_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4648437",
   "metadata": {},
   "source": [
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87bc9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx where f=(x^2):\n",
      " tf.Tensor([4.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# GradientTape can only be applied on tf.Variable with dtype float \n",
    "x = tf.Variable([2.])\n",
    "\n",
    "with tf.GradientTape(persistent=False, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2\n",
    "    \n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5de10212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx where f=(x^2):\n",
      " None\n",
      "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "The gradient df/dx where f=(x^2):\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#otherwise\n",
    "x = tf.constant([2.0]) #constant\n",
    "\n",
    "with tf.GradientTape(persistent=False, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2\n",
    "    \n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))\n",
    "\n",
    "x = tf.Variable([2]) #non float\n",
    "\n",
    "with tf.GradientTape(persistent=False, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2\n",
    "    \n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1fcc8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx where f=(x^2):\n",
      " tf.Tensor([4.], shape=(1,), dtype=float32)\n",
      "The gradient dh/dx where h=(x^3):\n",
      " tf.Tensor([27.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2.0])\n",
    "y = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2\n",
    "    h = y ** 3\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))\n",
    "print('The gradient dh/dx where h=(x^3):\\n', tape.gradient(h, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1459cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx where f=(x^2):\n",
      " tf.Tensor([4.], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Print gradient output\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe gradient df/dx where f=(x^2):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, tape\u001b[38;5;241m.\u001b[39mgradient(f, x))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe gradient dh/dx where h=(x^3):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1040\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;124;03m\"\"\"Computes the gradient using operations recorded in context of this tape.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \n\u001b[0;32m   1002\u001b[0m \u001b[38;5;124;03mNote: Unless you set `persistent=True` a GradientTape can only be used to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;124;03m   called with an unknown value.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1040\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA non-persistent GradientTape can only be used to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute one set of gradients (or jacobians)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recording:\n\u001b[0;32m   1043\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "source": [
    "# persistent = False can only be on first function\n",
    "x = tf.Variable([2.0])\n",
    "y = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=False, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2\n",
    "    h = y ** 3\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))\n",
    "print('The gradient dh/dx where h=(x^3):\\n', tape.gradient(h, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "664fd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx where f=(x^2):\n",
      " tf.Tensor([4.], shape=(1,), dtype=float32)\n",
      "The gradient dh/dx where h=(x^3):\n",
      " tf.Tensor([27.], shape=(1,), dtype=float32)\n",
      "The gradient df/dx where f=(x^2):\n",
      " None\n",
      "The gradient dh/dx where h=(x^3):\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#watch_accessed_variables=False, only check watched variable\n",
    "x = tf.Variable([2.0])\n",
    "y = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n",
    "    tape.watch([x,y])\n",
    "    f = x ** 2\n",
    "    h = y ** 3\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))\n",
    "print('The gradient dh/dx where h=(x^3):\\n', tape.gradient(h, y))\n",
    "\n",
    "with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n",
    "    f = x ** 2\n",
    "    h = y ** 3\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dx where f=(x^2):\\n', tape.gradient(f, x))\n",
    "print('The gradient dh/dx where h=(x^3):\\n', tape.gradient(h, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "448a0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dx and df/dy where f=(x^2*y+y+2):\n",
      " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([12.], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# gradient on multi-variable function\n",
    "x = tf.Variable([2.0])\n",
    "y = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2 * y + y + 2\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dx and df/dy where f=(x^2*y+y+2):\\n', tape.gradient(f, [x,y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62559f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient df/dy where f=(x^2*y+y+2):\n",
      " tf.Tensor([12.], shape=(1,), dtype=float32)\n",
      "The gradient df/dy where f=(x^2*y+y+2):\n",
      " tf.Tensor([5.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2.0])\n",
    "y = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
    "    f = x ** 2 * y + y + 2\n",
    "\n",
    "# Print gradient output\n",
    "print('The gradient df/dy where f=(x^2*y+y+2):\\n', tape.gradient(f, x))\n",
    "print('The gradient df/dy where f=(x^2*y+y+2):\\n', tape.gradient(f, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2d1f4",
   "metadata": {},
   "source": [
    "## Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d030164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b717bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    \"\"\"\n",
    "    input: x\n",
    "    output: y = 0.7x - 42 goal to fit\n",
    "    \"\"\"\n",
    "    return 0.7*X - 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba688e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "noise_level = 0.8\n",
    "trainX = np.linspace(165, 190, N)\n",
    "np.random.shuffle(trainX)\n",
    "trainY = f(trainX) + np.random.randn(N) * noise_level\n",
    "\n",
    "learning_rate = 0.1\n",
    "training_epochs = 300\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6bf51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bbca9d46a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(trainX, trainY, label='Original data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e347bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_forward(x, w, b):\n",
    "    return x * w + b\n",
    "\n",
    "def loss_fuction(y, y_hat):\n",
    "    return tf.reduce_mean(tf.square(y-y_hat))\n",
    "\n",
    "def data_loader(x, y, batch_size, shuffle=True):\n",
    "    ind = list(range(len(x)))\n",
    "    if shuffle == True:\n",
    "        np.random.shuffle(ind)\n",
    "    for i in range(0, len(ind), batch_size):\n",
    "        idx = np.array(ind[i:min(i+batch_size, len(x))])\n",
    "        yield x[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec139767",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(np.random.randn())\n",
    "b = tf.Variable(np.random.randn())\n",
    "batch_size = 32\n",
    "\n",
    "trainX = np.reshape(trainX, (-1,1))\n",
    "trainY = np.reshape(trainY, (-1,1))\n",
    "trainX, testX, trainY, testY = train_test_split(trainX, \n",
    "                                                trainY, \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51011692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing: normalize\n",
    "# trainX = (trainX - trainX.min()) / (trainX.max() - trainX.min())\n",
    "# trainY = (trainY - trainY.min()) / (trainY.max() - trainY.min())\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "trainX = x_scaler.fit_transform(trainX)\n",
    "trainY = y_scaler.fit_transform(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d445c58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bbcceedac0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(trainX, trainY, label='Original Data')\n",
    "plt.plot(trainX, lr_forward(trainX, w,b), c='y',label='Fitted Line')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcc2b5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.895207\n",
      "epoch 2, loss 0.264716\n",
      "epoch 3, loss 0.090641\n",
      "epoch 4, loss 0.041656\n",
      "epoch 5, loss 0.029466\n",
      "epoch 6, loss 0.027168\n",
      "epoch 7, loss 0.025521\n",
      "epoch 8, loss 0.025162\n",
      "epoch 9, loss 0.025067\n",
      "epoch 10, loss 0.025155\n",
      "epoch 11, loss 0.025109\n",
      "epoch 12, loss 0.025063\n",
      "epoch 13, loss 0.025091\n",
      "epoch 14, loss 0.025135\n",
      "epoch 15, loss 0.025054\n",
      "epoch 16, loss 0.025063\n",
      "epoch 17, loss 0.025084\n",
      "epoch 18, loss 0.025152\n",
      "epoch 19, loss 0.025087\n",
      "epoch 20, loss 0.025192\n",
      "epoch 21, loss 0.025120\n",
      "epoch 22, loss 0.025049\n",
      "epoch 23, loss 0.025134\n",
      "epoch 24, loss 0.025079\n",
      "epoch 25, loss 0.025054\n",
      "epoch 26, loss 0.025070\n",
      "epoch 27, loss 0.025066\n",
      "epoch 28, loss 0.025121\n",
      "epoch 29, loss 0.025077\n",
      "epoch 30, loss 0.025067\n",
      "epoch 31, loss 0.025064\n",
      "epoch 32, loss 0.025156\n",
      "epoch 33, loss 0.025054\n",
      "epoch 34, loss 0.025113\n",
      "epoch 35, loss 0.025165\n",
      "epoch 36, loss 0.025338\n",
      "epoch 37, loss 0.025147\n",
      "epoch 38, loss 0.025169\n",
      "epoch 39, loss 0.025108\n",
      "epoch 40, loss 0.025050\n",
      "epoch 41, loss 0.025087\n",
      "epoch 42, loss 0.025053\n",
      "epoch 43, loss 0.025058\n",
      "epoch 44, loss 0.025084\n",
      "epoch 45, loss 0.025075\n",
      "epoch 46, loss 0.025066\n",
      "epoch 47, loss 0.025107\n",
      "epoch 48, loss 0.025174\n",
      "epoch 49, loss 0.025055\n",
      "epoch 50, loss 0.025110\n",
      "epoch 51, loss 0.025084\n",
      "epoch 52, loss 0.025128\n",
      "epoch 53, loss 0.025129\n",
      "epoch 54, loss 0.025221\n",
      "epoch 55, loss 0.025061\n",
      "epoch 56, loss 0.025062\n",
      "epoch 57, loss 0.025068\n",
      "epoch 58, loss 0.025118\n",
      "epoch 59, loss 0.025187\n",
      "epoch 60, loss 0.025129\n",
      "epoch 61, loss 0.025105\n",
      "epoch 62, loss 0.025086\n",
      "epoch 63, loss 0.025062\n",
      "epoch 64, loss 0.025068\n",
      "epoch 65, loss 0.025048\n",
      "epoch 66, loss 0.025116\n",
      "epoch 67, loss 0.025251\n",
      "epoch 68, loss 0.025069\n",
      "epoch 69, loss 0.025341\n",
      "epoch 70, loss 0.025060\n",
      "epoch 71, loss 0.025065\n",
      "epoch 72, loss 0.025069\n",
      "epoch 73, loss 0.025075\n",
      "epoch 74, loss 0.025128\n",
      "epoch 75, loss 0.025053\n",
      "epoch 76, loss 0.025094\n",
      "epoch 77, loss 0.025052\n",
      "epoch 78, loss 0.025052\n",
      "epoch 79, loss 0.025138\n",
      "epoch 80, loss 0.025058\n",
      "epoch 81, loss 0.025054\n",
      "epoch 82, loss 0.025063\n",
      "epoch 83, loss 0.025104\n",
      "epoch 84, loss 0.025062\n",
      "epoch 85, loss 0.025051\n",
      "epoch 86, loss 0.025095\n",
      "epoch 87, loss 0.025073\n",
      "epoch 88, loss 0.025058\n",
      "epoch 89, loss 0.025157\n",
      "epoch 90, loss 0.025067\n",
      "epoch 91, loss 0.025151\n",
      "epoch 92, loss 0.025134\n",
      "epoch 93, loss 0.025122\n",
      "epoch 94, loss 0.025053\n",
      "epoch 95, loss 0.025105\n",
      "epoch 96, loss 0.025073\n",
      "epoch 97, loss 0.025105\n",
      "epoch 98, loss 0.025085\n",
      "epoch 99, loss 0.025096\n",
      "epoch 100, loss 0.025146\n",
      "epoch 101, loss 0.025213\n",
      "epoch 102, loss 0.025197\n",
      "epoch 103, loss 0.025057\n",
      "epoch 104, loss 0.025106\n",
      "epoch 105, loss 0.025086\n",
      "epoch 106, loss 0.025052\n",
      "epoch 107, loss 0.025208\n",
      "epoch 108, loss 0.025148\n",
      "epoch 109, loss 0.025070\n",
      "epoch 110, loss 0.025224\n",
      "epoch 111, loss 0.025051\n",
      "epoch 112, loss 0.025157\n",
      "epoch 113, loss 0.025190\n",
      "epoch 114, loss 0.025066\n",
      "epoch 115, loss 0.025074\n",
      "epoch 116, loss 0.025146\n",
      "epoch 117, loss 0.025282\n",
      "epoch 118, loss 0.025056\n",
      "epoch 119, loss 0.025138\n",
      "epoch 120, loss 0.025110\n",
      "epoch 121, loss 0.025094\n",
      "epoch 122, loss 0.025079\n",
      "epoch 123, loss 0.025126\n",
      "epoch 124, loss 0.025048\n",
      "epoch 125, loss 0.025083\n",
      "epoch 126, loss 0.025214\n",
      "epoch 127, loss 0.025098\n",
      "epoch 128, loss 0.025255\n",
      "epoch 129, loss 0.025274\n",
      "epoch 130, loss 0.025053\n",
      "epoch 131, loss 0.025059\n",
      "epoch 132, loss 0.025049\n",
      "epoch 133, loss 0.025050\n",
      "epoch 134, loss 0.025062\n",
      "epoch 135, loss 0.025088\n",
      "epoch 136, loss 0.025086\n",
      "epoch 137, loss 0.025282\n",
      "epoch 138, loss 0.025162\n",
      "epoch 139, loss 0.025050\n",
      "epoch 140, loss 0.025052\n",
      "epoch 141, loss 0.025075\n",
      "epoch 142, loss 0.025081\n",
      "epoch 143, loss 0.025114\n",
      "epoch 144, loss 0.025057\n",
      "epoch 145, loss 0.025063\n",
      "epoch 146, loss 0.025048\n",
      "epoch 147, loss 0.025052\n",
      "epoch 148, loss 0.025099\n",
      "epoch 149, loss 0.025226\n",
      "epoch 150, loss 0.025093\n",
      "epoch 151, loss 0.025056\n",
      "epoch 152, loss 0.025065\n",
      "epoch 153, loss 0.025220\n",
      "epoch 154, loss 0.025068\n",
      "epoch 155, loss 0.025050\n",
      "epoch 156, loss 0.025065\n",
      "epoch 157, loss 0.025094\n",
      "epoch 158, loss 0.025178\n",
      "epoch 159, loss 0.025157\n",
      "epoch 160, loss 0.025069\n",
      "epoch 161, loss 0.025132\n",
      "epoch 162, loss 0.025059\n",
      "epoch 163, loss 0.025111\n",
      "epoch 164, loss 0.025094\n",
      "epoch 165, loss 0.025148\n",
      "epoch 166, loss 0.025157\n",
      "epoch 167, loss 0.025053\n",
      "epoch 168, loss 0.025066\n",
      "epoch 169, loss 0.025143\n",
      "epoch 170, loss 0.025353\n",
      "epoch 171, loss 0.025147\n",
      "epoch 172, loss 0.025078\n",
      "epoch 173, loss 0.025108\n",
      "epoch 174, loss 0.025068\n",
      "epoch 175, loss 0.025071\n",
      "epoch 176, loss 0.025102\n",
      "epoch 177, loss 0.025080\n",
      "epoch 178, loss 0.025120\n",
      "epoch 179, loss 0.025068\n",
      "epoch 180, loss 0.025053\n",
      "epoch 181, loss 0.025061\n",
      "epoch 182, loss 0.025173\n",
      "epoch 183, loss 0.025118\n",
      "epoch 184, loss 0.025100\n",
      "epoch 185, loss 0.025077\n",
      "epoch 186, loss 0.025066\n",
      "epoch 187, loss 0.025077\n",
      "epoch 188, loss 0.025065\n",
      "epoch 189, loss 0.025120\n",
      "epoch 190, loss 0.025076\n",
      "epoch 191, loss 0.025120\n",
      "epoch 192, loss 0.025170\n",
      "epoch 193, loss 0.025095\n",
      "epoch 194, loss 0.025067\n",
      "epoch 195, loss 0.025076\n",
      "epoch 196, loss 0.025141\n",
      "epoch 197, loss 0.025062\n",
      "epoch 198, loss 0.025066\n",
      "epoch 199, loss 0.025093\n",
      "epoch 200, loss 0.025076\n",
      "epoch 201, loss 0.025068\n",
      "epoch 202, loss 0.025116\n",
      "epoch 203, loss 0.025057\n",
      "epoch 204, loss 0.025198\n",
      "epoch 205, loss 0.025063\n",
      "epoch 206, loss 0.025096\n",
      "epoch 207, loss 0.025111\n",
      "epoch 208, loss 0.025090\n",
      "epoch 209, loss 0.025110\n",
      "epoch 210, loss 0.025187\n",
      "epoch 211, loss 0.025130\n",
      "epoch 212, loss 0.025165\n",
      "epoch 213, loss 0.025083\n",
      "epoch 214, loss 0.025115\n",
      "epoch 215, loss 0.025111\n",
      "epoch 216, loss 0.025090\n",
      "epoch 217, loss 0.025222\n",
      "epoch 218, loss 0.025251\n",
      "epoch 219, loss 0.025110\n",
      "epoch 220, loss 0.025231\n",
      "epoch 221, loss 0.025074\n",
      "epoch 222, loss 0.025061\n",
      "epoch 223, loss 0.025059\n",
      "epoch 224, loss 0.025123\n",
      "epoch 225, loss 0.025195\n",
      "epoch 226, loss 0.025387\n",
      "epoch 227, loss 0.025264\n",
      "epoch 228, loss 0.025060\n",
      "epoch 229, loss 0.025066\n",
      "epoch 230, loss 0.025060\n",
      "epoch 231, loss 0.025069\n",
      "epoch 232, loss 0.025056\n",
      "epoch 233, loss 0.025095\n",
      "epoch 234, loss 0.025209\n",
      "epoch 235, loss 0.025156\n",
      "epoch 236, loss 0.025062\n",
      "epoch 237, loss 0.025056\n",
      "epoch 238, loss 0.025053\n",
      "epoch 239, loss 0.025194\n",
      "epoch 240, loss 0.025057\n",
      "epoch 241, loss 0.025070\n",
      "epoch 242, loss 0.025067\n",
      "epoch 243, loss 0.025069\n",
      "epoch 244, loss 0.025100\n",
      "epoch 245, loss 0.025061\n",
      "epoch 246, loss 0.025126\n",
      "epoch 247, loss 0.025050\n",
      "epoch 248, loss 0.025102\n",
      "epoch 249, loss 0.025120\n",
      "epoch 250, loss 0.025199\n",
      "epoch 251, loss 0.025082\n",
      "epoch 252, loss 0.025108\n",
      "epoch 253, loss 0.025160\n",
      "epoch 254, loss 0.025357\n",
      "epoch 255, loss 0.025358\n",
      "epoch 256, loss 0.025279\n",
      "epoch 257, loss 0.025065\n",
      "epoch 258, loss 0.025220\n",
      "epoch 259, loss 0.025126\n",
      "epoch 260, loss 0.025069\n",
      "epoch 261, loss 0.025056\n",
      "epoch 262, loss 0.025150\n",
      "epoch 263, loss 0.025150\n",
      "epoch 264, loss 0.025079\n",
      "epoch 265, loss 0.025087\n",
      "epoch 266, loss 0.025112\n",
      "epoch 267, loss 0.025102\n",
      "epoch 268, loss 0.025084\n",
      "epoch 269, loss 0.025154\n",
      "epoch 270, loss 0.025071\n",
      "epoch 271, loss 0.025052\n",
      "epoch 272, loss 0.025075\n",
      "epoch 273, loss 0.025067\n",
      "epoch 274, loss 0.025052\n",
      "epoch 275, loss 0.025059\n",
      "epoch 276, loss 0.025110\n",
      "epoch 277, loss 0.025093\n",
      "epoch 278, loss 0.025064\n",
      "epoch 279, loss 0.025095\n",
      "epoch 280, loss 0.025080\n",
      "epoch 281, loss 0.025164\n",
      "epoch 282, loss 0.025053\n",
      "epoch 283, loss 0.025065\n",
      "epoch 284, loss 0.025058\n",
      "epoch 285, loss 0.025089\n",
      "epoch 286, loss 0.025080\n",
      "epoch 287, loss 0.025096\n",
      "epoch 288, loss 0.025061\n",
      "epoch 289, loss 0.025060\n",
      "epoch 290, loss 0.025220\n",
      "epoch 291, loss 0.025052\n",
      "epoch 292, loss 0.025108\n",
      "epoch 293, loss 0.025071\n",
      "epoch 294, loss 0.025151\n",
      "epoch 295, loss 0.025160\n",
      "epoch 296, loss 0.025109\n",
      "epoch 297, loss 0.025092\n",
      "epoch 298, loss 0.025119\n",
      "epoch 299, loss 0.025096\n",
      "epoch 300, loss 0.025118\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_epochs):\n",
    "    for X, y in data_loader(trainX, trainY, batch_size):\n",
    "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
    "            #get loss for current batch\n",
    "            loss = loss_fuction(y, lr_forward(X, w, b))\n",
    "            \n",
    "        #get gradient, update parameter\n",
    "        delta_w, delta_b = tape.gradient(loss, [w, b])\n",
    "        w.assign_sub(learning_rate * delta_w)\n",
    "        b.assign_sub(learning_rate * delta_b)\n",
    "    \n",
    "    #get total loss\n",
    "    train_loss = loss_fuction(trainY, lr_forward(trainX, w, b))\n",
    "    print('epoch %d, loss %f' % (i+1, tf.reduce_mean(train_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14666557",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_x = x_scaler.transform(np.reshape(testX, (-1, 1)))\n",
    "predicted_y = y_scaler.inverse_transform(lr_forward(processed_x, w,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f42aeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756947331358382"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(testY, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e58bd82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bbcdf37f70>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(trainX, trainY, label='Original Data')\n",
    "plt.plot(trainX, lr_forward(trainX, w,b), c='y',label='Fitted Line')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2113eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.9909252>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.007621241>\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d79106c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.7004467], shape=(1,), dtype=float32)\n",
      "tf.Tensor([-42.185417], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(w * y_scaler.scale_ / x_scaler.scale_)\n",
    "print(- w * y_scaler.scale_ / x_scaler.scale_ * x_scaler.mean_ + y_scaler.scale_ * b + y_scaler.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af5c0e",
   "metadata": {},
   "source": [
    "## Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "394d5a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1, input_dim=1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a5e7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 2s 1ms/step - loss: 0.0351 - mse: 0.0351\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 959us/step - loss: 0.0323 - mse: 0.0323\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 995us/step - loss: 0.0289 - mse: 0.0289\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 996us/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 993us/step - loss: 0.0271 - mse: 0.0271\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 934us/step - loss: 0.0265 - mse: 0.0265\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 794us/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 882us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 764us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 904us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 699us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 883us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 714us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 861us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 854us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 706us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 962us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 870us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 883us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 774us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 906us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 987us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 779us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 717us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 987us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 822us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 742us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 990us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 715us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 853us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 889us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 840us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 677us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 765us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 954us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 966us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 879us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 882us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 952us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 943us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 926us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 839us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 854us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 786us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 920us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 900us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 850us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 860us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 853us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 710us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 853us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 870us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 710us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 762us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 849us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 792us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 709us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 662us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 707us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 703us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 881us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 575us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 708us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 821us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 854us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 709us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 576us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 570us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 853us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 850us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 854us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 724us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 851us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 853us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 709us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 711us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 704us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 715us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 793us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 712us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 716us/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 777us/step - loss: 0.0251 - mse: 0.0251\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics='mse')\n",
    "history = model.fit(trainX, trainY, steps_per_epoch=8, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "628ce977",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_x = x_scaler.transform(np.reshape(testX, (-1, 1)))\n",
    "predicted_y = y_scaler.inverse_transform(model(processed_x.astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7452a7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757123334577587"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(testY, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31c29b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.9870833]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.00017185], dtype=float32)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8f5e6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9870833]], dtype=float32), array([0.00017185], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3d6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
